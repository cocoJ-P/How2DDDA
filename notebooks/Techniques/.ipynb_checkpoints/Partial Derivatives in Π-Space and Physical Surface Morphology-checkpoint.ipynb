{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5196cdae-041c-4d78-a89d-7ca05e33e69a",
   "metadata": {},
   "source": [
    "# üí° How2DDDA: **\"Partial Derivatives in Œ†-Space and Physical Surface Morphology\"**\n",
    "\n",
    "> All code and examples are shared to help researchers, students, and engineers understand the reasoning behind DDDA ‚Äî and to make it easy to apply dimensional analysis to your own data.  \n",
    "> This notebook serves as an entry-level guide for teaching, validating physical models, and enabling domain-specific knowledge engineering through data-driven dimensional reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "**Œ†-Á©∫Èó¥ÂÅèÂØº‰∏éÁâ©ÁêÜÊõ≤Èù¢ÂΩ¢ÊÄÅ**\n",
    "\n",
    "In this notebook, we will walk through the theoretical and computational foundation of **dimensional analysis**, with a focus on the **Buckingham Pi theorem**. You will learn:\n",
    "\n",
    "1. **The motivation behind dimensional analysis**  \n",
    "   Understand why we reduce variables and how dimensional consistency enables model generalization.\n",
    "\n",
    "2. **How to construct the dimensional matrix (D-matrix)**  \n",
    "   Encode physical units of input quantities using base units and build the D-matrix.\n",
    "\n",
    "3. **How to compute Œ†-groups using null space techniques**  \n",
    "   Discover dimensionless groups by solving linear algebraic equations on the D-matrix.\n",
    "\n",
    "4. **How to interpret and validate Œ†-groups**  \n",
    "   Learn to assess whether derived groups make physical and computational sense.\n",
    "\n",
    "5. **How to extend the method toward data-driven workflows**  \n",
    "   Set the stage for further steps in the DDDA pipeline including Pi-group selection, uncertainty quantification, and regime detection.\n",
    "\n",
    "---\n",
    "\n",
    "## üë§ Author\n",
    "\n",
    "- **Name**: Jiashun Pang  \n",
    "- **Created**: August 2025  \n",
    "- **Affiliation**: DDDA Project, open research notebook  \n",
    "- **Notebook Focus**:  \n",
    "  A hands-on exploration of dimensional analysis ‚Äî from aggregated raw quantities to symbolic Pi-group discovery and preparation for downstream DDDA tasks.\n",
    "\n",
    "---\n",
    "\n",
    "üìå *This notebook is designed to be accessible for learners new to dimensional analysis, while also laying the foundation for advanced applications in the full DDDA pipeline.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282c0c1-fb22-4370-9e82-b21abc728aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8ee38-db6d-4613-8f3b-494457df77c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ced1f-1bbb-46ec-ab4c-9fe79bf9e5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a116553c-039b-4d08-98ea-ee711b081715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Re</th>\n",
       "      <th>log10Re</th>\n",
       "      <th>CD_clean</th>\n",
       "      <th>CD_noisy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>23.601582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.023332</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>23.652792</td>\n",
       "      <td>23.435312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.047209</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>23.118060</td>\n",
       "      <td>23.862418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.071643</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>22.595520</td>\n",
       "      <td>22.705094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.096647</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>22.084895</td>\n",
       "      <td>22.592975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Re   log10Re   CD_clean   CD_noisy\n",
       "0  1.000000  0.000000  24.200000  23.601582\n",
       "1  1.023332  0.010017  23.652792  23.435312\n",
       "2  1.047209  0.020033  23.118060  23.862418\n",
       "3  1.071643  0.030050  22.595520  22.705094\n",
       "4  1.096647  0.040067  22.084895  22.592975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 2 ¬∑ Synthetic Data I: C_D‚ÄìRe prototype\n",
    "# - Defines a reusable generator\n",
    "# - Creates a sample dataset\n",
    "# - Saves CSV and draws a quick diagnostic plot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "def simulate_cd_re(\n",
    "    n_points: int = 500,\n",
    "    re_min: float = 1e0,\n",
    "    re_max: float = 1e6,\n",
    "    re_c: float = 3e5,\n",
    "    A: float = 24.0,\n",
    "    p: float = 1.0,\n",
    "    B: float = 0.2,\n",
    "    D: float = 0.15,\n",
    "    sigma_decades: float = 0.35,\n",
    "    noise_rel: float = 0.03,\n",
    "    noise_abs: float = 0.0,\n",
    "    seed: int = 42,\n",
    "    grid: str = \"log\",\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate a synthetic C_D(Re) dataset with a controllable minimum near re_c.\n",
    "\n",
    "    Clean model:\n",
    "        C_D_clean(Re) = A / Re^p + B + D * s((log10(Re) - log10(re_c)) / sigma_decades)\n",
    "        where s(x) = (1 + tanh(x)) / 2  (smooth sigmoid)\n",
    "\n",
    "    Returns a DataFrame with columns: [\"Re\", \"log10Re\", \"CD_clean\", \"CD_noisy\"].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if grid == \"log\":\n",
    "        Re = np.logspace(np.log10(re_min), np.log10(re_max), n_points)\n",
    "    elif grid == \"lin\":\n",
    "        Re = np.linspace(re_min, re_max, n_points)\n",
    "    else:\n",
    "        raise ValueError(\"grid must be 'log' or 'lin'\")\n",
    "\n",
    "    logRe = np.log10(Re)\n",
    "    x = (logRe - np.log10(re_c)) / sigma_decades\n",
    "    sigmoid = 0.5 * (1.0 + np.tanh(x))\n",
    "\n",
    "    CD_clean = A / (Re ** p) + B + D * sigmoid\n",
    "\n",
    "    # Noise model: combine relative and absolute components (in quadrature)\n",
    "    noise_std = np.sqrt((noise_rel * CD_clean) ** 2 + (noise_abs ** 2))\n",
    "    noise = rng.normal(loc=0.0, scale=noise_std)\n",
    "    CD_noisy = CD_clean + noise\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Re\": Re,\n",
    "        \"log10Re\": logRe,\n",
    "        \"CD_clean\": CD_clean,\n",
    "        \"CD_noisy\": CD_noisy\n",
    "    })\n",
    "\n",
    "    meta = {\n",
    "        \"re_min\": re_min, \"re_max\": re_max, \"re_c\": re_c, \"A\": A, \"p\": p, \"B\": B,\n",
    "        \"D\": D, \"sigma_decades\": sigma_decades, \"noise_rel\": noise_rel,\n",
    "        \"noise_abs\": noise_abs, \"seed\": seed, \"grid\": grid\n",
    "    }\n",
    "    return df, meta\n",
    "\n",
    "# --- Example usage ---\n",
    "df, meta = simulate_cd_re(\n",
    "    n_points=600,\n",
    "    re_min=1e0,\n",
    "    re_max=1e6,\n",
    "    re_c=3e5,          # minimum sits near this Re\n",
    "    A=24.0,\n",
    "    p=1.0,\n",
    "    B=0.2,\n",
    "    D=0.18,\n",
    "    sigma_decades=0.35,\n",
    "    noise_rel=0.025,\n",
    "    noise_abs=0.0,\n",
    "    seed=123,\n",
    "    grid=\"log\"\n",
    ")\n",
    "\n",
    "# Save for later sections\n",
    "df.to_csv(\"cd_re_synthetic.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94743b5-3a59-4b6c-a2d3-df6cd8898ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
